# -*- coding: utf-8 -*-
"""Virtifier_Ex3_Research.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bmSkBF1FJ-dyhcf2ognybsTuRrN19mu1
"""

# For this upload .fasta data from PC
# Merge all the data and name it as merged_sequences.fasta
# Data downloaded from NCBI website: https://www.ncbi.nlm.nih.gov/labs/virus/vssi/#/virus?SeqType_s=Nucleotide&VirusLineage_ss=Severe%20acute%20respiratory%20syndrome%20coronavirus%202,%20taxid:2697049&SourceDB_s=GenBank&Completeness_s=complete&CollectionDate_dr=2020-01-01T00:00:00.00Z%20TO%202025-03-02T23:59:59.00Z

pip install tensorflow biopython numpy scikit-learn

import numpy as np
from Bio import SeqIO
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Embedding, SpatialDropout1D
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from tensorflow.keras.preprocessing.text import Tokenizer

from google.colab import files
# Opens a file upload dialog
uploaded = files.upload()

import os

merged_filename = "merged_sequences.fasta"
# Append all the files
# Add a new line for separation
with open(merged_filename, "w") as outfile:
    for file_name in uploaded.keys():
        with open(file_name, "r") as infile:
            outfile.write(infile.read())
            outfile.write("\n")  # Add a newline for separation

print(f"All FASTA files have been merged into '{merged_filename}'")

# Check the fasta file
!head merged_sequences.fasta

# Load DNA sequences and labels from the merged FASTA file
def load_sequences(file_path):
    sequences = []
    labels = []
    for record in SeqIO.parse(file_path, "fasta"):
        sequences.append(str(record.seq))
        labels.append(record.id)
    return sequences, labels

# Tokenize sequences using a simple tokenizer
# char_level=True to handle nucleotide characters
def tokenize_sequences(sequences):
    tokenizer = Tokenizer(char_level=True)
    tokenizer.fit_on_texts(sequences)
    sequences_int = tokenizer.texts_to_sequences(sequences)
    return sequences_int, tokenizer

# Pad sequences to make sure that they are of equal length for LSTM input
def pad_sequence_data(sequences_int, max_length=1000):
    return pad_sequences(sequences_int, maxlen=max_length, padding='post')

# Build and compile an LSTM model.
def build_lstm_model(input_length, vocab_size, embedding_dim=100, lstm_units=100):
    model = Sequential()
    model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=input_length))
    model.add(SpatialDropout1D(0.2))
    model.add(LSTM(lstm_units, dropout=0.2, recurrent_dropout=0.2))
    model.add(Dense(1, activation='sigmoid'))
    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model

# Example of training and evaluating the model
# Train the LSTM model and evaluate its performance.
def train_and_evaluate_model(X, y):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Create and initialize an LSTM model by passing the input sequence length (X.shape[1])
    # and the vocabulary size (np.max(X) + 1,
    # which is the highest integer value in the tokenized sequences plus one)
    # to the build_lstm_model function
    model = build_lstm_model(input_length=X.shape[1], vocab_size=np.max(X) + 1)

    model.summary()

    # Train the model
    model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_test, y_test), verbose=1)

    # Evaluate the model
    # Convert probabilities to binary predictions
    y_pred = (model.predict(X_test) > 0.5).astype(int)
    print(f"Accuracy: {accuracy_score(y_test, y_pred)}")

# Virtifier-inspired model
def main(file_path):
    # Load DNA sequences and labels
    sequences, labels = load_sequences(file_path)

    # convert characters into integers -- Tokenize
    sequences_int, tokenizer = tokenize_sequences(sequences)

    # Pad sequences to make sure that the sequences are of equal length
    X = pad_sequence_data(sequences_int, max_length=1000)

    # Convert the labels into binary values where 1 is viral and 0 is not viral
    # First convert to lower case
    # if the label contains the word viral make it 1, if not 0
    y = np.array([1 if 'viral' in label.lower() else 0 for label in labels])

    # Train and evaluate the model
    train_and_evaluate_model(X, y)

# Run pipeline
if __name__ == "__main__":
    file_path = "merged_sequences.fasta"
    main(file_path)