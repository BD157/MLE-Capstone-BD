# -*- coding: utf-8 -*-
"""Word2Vec Ex1 Research.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UKBT3wA9Fgb1xTdoU9L0T3oUM4EZsNi_
"""

# The code fetches COVID-19 and non-COVID-19 protein sequences directly from NCBI using the Entrez API,
# processes them into k-mers, and trains machine learning models for classification.
# Email sign in required for fetching data

!pip install biopython

import numpy as np
import pandas as pd
from Bio import Entrez, SeqIO
from gensim.models import Word2Vec
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.metrics import accuracy_score

# Email for NCBI Entrez
# Entrez.email = "use your email id"

# Function to fetch sequences from NCBI
# This function searches NCBI's protein database for sequences related to covid-19 and
# Flu in this case. It downloads 500 protein sequences,
# extracts their genetic code, and breaks them into trigrams (set of 3)
# for analysis. It also labels the sequences: 1 for covid and 0 for non-covid in this case flu,
# so they can be used to train an ML model to recognize which ones are COVID-19 proteins
# and which ones are not.

def fetch_ncbi_sequences(query, retmax=500):
    handle = Entrez.esearch(db="protein", term=query, retmax=retmax)
    record = Entrez.read(handle)
    handle.close()
    ids = record["IdList"]

    sequences = []
    labels = []
    for seq_id in ids:
        fetch_handle = Entrez.efetch(db="protein", id=seq_id, rettype="fasta", retmode="text")
        seq_record = SeqIO.read(fetch_handle, "fasta")
        fetch_handle.close()
        sequences.append(get_kmers(str(seq_record.seq)))
        labels.append(1 if "COVID-19" in seq_record.description else 0)

    return sequences, labels

# Function to generate k-mers
# In this case it is 3.
# Splits the sequence into smaller pieces, called k-mers, each containing 3 consecutive letters.
def get_kmers(sequence, k=3):
    return [sequence[i:i+k] for i in range(len(sequence) - k + 1)]

# Get covid-19 and flu datasets from NCBI
covid_sequences, covid_labels = fetch_ncbi_sequences("SARS-CoV-2[Organism]", retmax=500)
non_covid_sequences, non_covid_labels = fetch_ncbi_sequences("Influenza[Organism]", retmax=500)

# Combine datasets
sequences = covid_sequences + non_covid_sequences
labels = np.array(covid_labels + non_covid_labels)

# Train Word2Vec model
# CBOW model
w2v_model = Word2Vec(sequences, vector_size=200, window=5, min_count=1, sg=0)

# convert the genetic sequences into numerical representations (vectors)
# by averaging the values of smaller pieces (k-mers) using a trained model
# then stores the results as an array.
def vectorize_sequence(sequence, model):
    vec = np.mean([model.wv[kmer] for kmer in sequence if kmer in model.wv], axis=0)
    return vec if vec is not None else np.zeros(200)

X = np.array([vectorize_sequence(seq, w2v_model) for seq in sequences])

# Standardization
# Adjust the data by removing its average and scale it based on spread.
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Dimensionality Reduction with PCA
# Simplify the data by reducing the number of features
# Keep the most important features
# compress the data into 10 key components for easier analysis.
pca = PCA(n_components=10)
X_pca = pca.fit_transform(X_scaled)

# Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X_pca, labels, test_size=0.3, random_state=42)

# Machine Learning Models
models = {
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "SVM": SVC(kernel='linear', probability=True),
    "KNN": KNeighborsClassifier(n_neighbors=5),
    "Logistic Regression": LogisticRegression(),
    "LDA": LinearDiscriminantAnalysis()
}

# Train and Evaluate Models
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print(f"{name} Accuracy: {accuracy:.4f}")